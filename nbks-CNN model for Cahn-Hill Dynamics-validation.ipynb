{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import OrderedDict, defaultdict\n",
    "from toolz.curried import pipe, curry, compose\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chnet.ch_tools as ch_tools\n",
    "from chnet.ch_losses import *\n",
    "import chnet.utilities as ch_utils\n",
    "import chnet.ch_generator as ch_gen\n",
    "from chnet.torchsummary import summary\n",
    "from chnet.ch_loader import CahnHillDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = [8.0, 6.0]\n",
    "mpl.rcParams['figure.dpi'] = 80\n",
    "mpl.rcParams['savefig.dpi'] = 100\n",
    "\n",
    "mpl.rcParams['font.size'] = 12\n",
    "mpl.rcParams['legend.fontsize'] = 'large'\n",
    "mpl.rcParams['figure.titlesize'] = 'medium'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(unet, input_size=(1, 128, 128))\n",
    "# summary(unet_solo_resloop, input_size=(1, 128, 128))\n",
    "# summary(unet_loop, input_size=(3, 1, 128, 128))\n",
    "# summary(unet_res, input_size=(1, 128, 128))\n",
    "# summary(unet_resloop, input_size=(3, 1, 128, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Process Parameters\n",
    "mid=0.0\n",
    "dif=0.449\n",
    "dim_x=96\n",
    "init_steps=1\n",
    "nstep=2\n",
    "dx=0.25 # not from paper\n",
    "dt=0.01 # from paper\n",
    "gamma=0.2 # from paper\n",
    "m_l=mid-dif, \n",
    "m_r=mid+dif,\n",
    "seed_trn=110364\n",
    "n_samples_val=512\n",
    "\n",
    "def mae_loss_npy(x1, x2):\n",
    "    return np.mean(np.fabs(x1-x2))\n",
    "\n",
    "maerr = lambda x1, x2: np.fabs(x1-x2)\n",
    "diff = lambda x1,x2: np.log(maerr(x1, x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x_val, y_val = ch_gen.data_generator(nsamples=n_samples_val, \n",
    "                              dim_x=dim_x, \n",
    "                              init_steps=init_steps, \n",
    "                              delta_sim_steps = delta_sim_steps,\n",
    "                              dx=dx, \n",
    "                              dt=dt,\n",
    "                              m_l=m_l, \n",
    "                              m_r=m_r,\n",
    "                              n_step=nstep,\n",
    "                              gamma=gamma, \n",
    "                              seed=38921641,\n",
    "                              device=device)\n",
    "\n",
    "\n",
    "val_dataset = CahnHillDataset(x_val, y_val, transform_x=lambda x: x[:,None], transform_y=lambda x: x[:,None])\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=1)\n",
    "\n",
    "total_val_step = len(val_loader)\n",
    "print(\"No. of validation steps: %d\" % total_val_step)\n",
    "\n",
    "for ix in range(3):\n",
    "    ch_utils.draw_by_side([x_val[ix][0], y_val[ix][-1]], \n",
    "                          sub_titles=[\"training input\", \"training output\"], \n",
    "                          title=\"mean: {:1.3f}\".format(np.mean(x_val[ix])), \n",
    "                          vmax=None, \n",
    "                          vmin=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chnet.models import UNet, UNet_solo_loop, UNet_loop, mse_loss\n",
    "# obj = torch.load(\"weights/model_unet_size_64_step_2_init_1_delta_2500_tstep_250.pt\")\n",
    "# model = UNet(in_channels=1, out_channels=1, init_features=64).double().to(device)\n",
    "# obj = torch.load(\"weights/model_unet_loop_size_64_step_4_init_1_delta_1250_tstep_250.pt\")\n",
    "# model = UNet_loop(in_channels=1, out_channels=1, init_features=64, temporal=4).double().to(device)\n",
    "# obj = torch.load(\"weights/model_unet_size_32_step_5_init_1_delta_1000.pt\")\n",
    "# model = UNet(in_channels=1, out_channels=1, init_features=32).double().to(device)\n",
    "# obj = torch.load(\"weights/model_unet_loop_size_16_step_5_init_1_delta_1000.pt\")\n",
    "# model = UNet_loop(in_channels=1, out_channels=1, init_features=16, temporal=nstep).double().to(device)\n",
    "# obj = torch.load(\"weights/model_unet_loop_size_32_step_5_init_1_delta_1000.pt\")\n",
    "# model = UNet_loop(in_channels=1, out_channels=1, init_features=32, temporal=nstep).double().to(device)\n",
    "# obj = torch.load(\"weights/model_unet_loop_size_32_step_10_init_1_delta_500_tstep_250.pt\")\n",
    "# model = UNet_loop(in_channels=1, out_channels=1, init_features=32, temporal=10).double().to(device)\n",
    "# obj = torch.load(\"weights/model_unet_solo_loop_size_16_step_5_init_1_delta_1000.pt\")\n",
    "# model = UNet_solo_loop(in_channels=1, out_channels=1, init_features=16, temporal=nstep).double().to(device)\n",
    "model.load_state_dict(obj[\"state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = torch.load(\"weights/model_unet_size_64_step_5_init_1_delta_100_tstep_250.pt\")\n",
    "model = UNet(in_channels=1, out_channels=1, init_features=64).double().to(device)\n",
    "model.load_state_dict(obj[\"state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "x_val, y_val = ch_gen.data_generator(nsamples=n_samples_val, \n",
    "                              dim_x=dim_x, \n",
    "                              init_steps=1, \n",
    "                              delta_sim_steps=250,\n",
    "                              dx=dx, \n",
    "                              dt=dt,\n",
    "                              m_l=m_l, \n",
    "                              m_r=m_r,\n",
    "                              n_step=2,\n",
    "                              gamma=gamma, \n",
    "                              seed=38921641,\n",
    "                              device=device)\n",
    "\n",
    "\n",
    "val_dataset = CahnHillDataset(x_val, y_val, transform_x=lambda x: x[:,None], transform_y=lambda x: x[:,None])\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=1)\n",
    "torch.cuda.empty_cache()\n",
    "model.eval()\n",
    "errs = []\n",
    "for ix in range(len(val_dataset)):\n",
    "\n",
    "    item_v = val_dataset[ix]\n",
    "\n",
    "    x = item_v['x'][None][:,0].double().to(device)\n",
    "    y_tru = item_v['y'][None][:,-1].double().to(device) \n",
    "    \n",
    "    if \"loop\" in key:\n",
    "        y_prd=model(x)[:,-1]\n",
    "    else:\n",
    "        y_prd=model(x)\n",
    "        \n",
    "    im_y1 = y_tru[0,0].detach().cpu().numpy()\n",
    "    im_y2 = y_prd[0,0].detach().cpu().numpy()\n",
    "    errs.append(mae_loss_npy(im_y1, im_y2))\n",
    "    print(\"mean conc. : {}, mae: {:1.5f}\".format(np.mean(im_y1), errs[-1]))\n",
    "    ch_utils.draw_by_side([im_y1, im_y2], \n",
    "                          sub_titles=[\"sim\", \"cnn\"], \n",
    "                          scale=8, vmin=None, vmax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chnet.models import UNet, UNet_solo_loop, UNet_loop, mse_loss\n",
    "err_dct = {}\n",
    "weight_files = [\"weights/model_unet_size_64_step_2_init_1_delta_250_tstep_250.pt\",\n",
    "                \"weights/model_unet_size_64_step_5_init_1_delta_100_tstep_250.pt\", \n",
    "                \"weights/model_unet_size_64_step_2_init_1_delta_500_tstep_250.pt\", \n",
    "                \"weights/model_unet_size_64_step_2_init_1_delta_1000_tstep_250.pt\",\n",
    "                \"weights/model_unet_size_64_step_2_init_1_delta_2500_tstep_250.pt\",\n",
    "                \"weights/model_unet_loop_size_64_step_2_init_1_delta_2500_tstep_250.pt\", \n",
    "                \"weights/model_unet_loop_size_64_step_4_init_1_delta_1250_tstep_250.pt\", \n",
    "                \"weights/model_unet_loop_size_64_step_5_init_1_delta_1000_tstep_250.pt\", \n",
    "                \"weights/model_unet_solo_loop_size_64_step_4_init_1_delta_1250_tstep_250.pt\"]\n",
    "\n",
    "tsteps = [500, 500, 1000, 2000, 5000, 5000, 5000, 5000, 5000]\n",
    "keys = [\"unet-500-spl\", \"unet-500\", \"unet-1k\", \"unet-2k\", \"unet-5k\", \"uloop-2\", \"uloop-4\", \"uloop-5\", \"usolo-4\"]\n",
    "\n",
    "from chnet.models import UNet, UNet_solo_loop, UNet_loop, mse_loss\n",
    "for key, weight, tstep in zip(keys[:2], weight_files[:2], tsteps[:2]):\n",
    "    print(key, weight)\n",
    "    x_val, y_val = ch_gen.data_generator(nsamples=n_samples_val, \n",
    "                                  dim_x=dim_x, \n",
    "                                  init_steps=1, \n",
    "                                  delta_sim_steps = tstep//2,\n",
    "                                  dx=dx, \n",
    "                                  dt=dt,\n",
    "                                  m_l=m_l, \n",
    "                                  m_r=m_r,\n",
    "                                  n_step=2,\n",
    "                                  gamma=gamma, \n",
    "                                  seed=38921641,\n",
    "                                  device=device)\n",
    "    val_dataset = CahnHillDataset(x_val, y_val, transform_x=lambda x: x[:,None], transform_y=lambda x: x[:,None])\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=1)\n",
    "    \n",
    "    obj = torch.load(weight)\n",
    "    if \"unet\" in key:\n",
    "        model = UNet(in_channels=1, out_channels=1, init_features=64).double().to(device)\n",
    "    elif \"uloop\" in key:\n",
    "        t = int(key.split(\"-\")[-1])\n",
    "        model = UNet_loop(in_channels=1, out_channels=1, init_features=64, temporal=t).double().to(device)\n",
    "    elif \"usolo\" in key:\n",
    "        t = int(key.split(\"-\")[-1])\n",
    "        model = UNet_solo_loop(in_channels=1, out_channels=1, init_features=64, temporal=t).double().to(device)\n",
    "    model.load_state_dict(obj[\"state\"])\n",
    "    \n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    model.eval()\n",
    "    errs = []\n",
    "    for ix in tqdm(range(len(val_dataset))):\n",
    "\n",
    "        item_v = val_dataset[ix]\n",
    "\n",
    "        x = item_v['x'][None][:,0].double().to(device)\n",
    "        y_tru = item_v['y'][None][:,-1].double().to(device) \n",
    "\n",
    "        if \"loop\" in key:\n",
    "            y_prd=model(x)[:,-1]\n",
    "        else:\n",
    "            y_prd=model(x)\n",
    "\n",
    "        im_y1 = y_tru[0,0].detach().cpu().numpy()\n",
    "        im_y2 = y_prd[0,0].detach().cpu().numpy()\n",
    "        errs.append(mae_loss_npy(im_y1, im_y2))\n",
    "#         print(\"mae: {:1.5f}\".format(errs[-1]))\n",
    "#         ch_utils.draw_by_side([im_y1, im_y2], \n",
    "#                               sub_titles=[\"sim\", \"cnn\"], \n",
    "#                               scale=8)\n",
    "    err_dct[key] = errs\n",
    "    print(np.mean(err_dct[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chnet.models import UNet, UNet_solo_loop, UNet_loop, mse_loss\n",
    "err_dct = {}\n",
    "weight_files = [\"weights/model_unet_size_64_step_2_init_1_delta_2500_tstep_250.pt\",\n",
    "                \"weights/model_unet_size_64_step_2_init_500_delta_2250_tstep_250.pt\", \n",
    "                \"weights/model_unet_size_64_step_2_init_1000_delta_2000_tstep_250.pt\", \n",
    "                \"weights/model_unet_size_64_step_2_init_2000_delta_1500_tstep_250.pt\",]\n",
    "\n",
    "delta_tsteps = [2500, 2250, 2000, 1500]\n",
    "init_steps = [1, 500, 1000, 2000]\n",
    "keys = [\"unet-i-1\", \"unet-i-500\", \"unet-i-1k\", \"unet-i-2k\"]\n",
    "\n",
    "for key, weight, dtstep, itstep in zip(keys, weight_files, delta_tsteps, init_steps):\n",
    "    print(key, weight)\n",
    "    x_val, y_val = ch_gen.data_generator(nsamples=n_samples_val, \n",
    "                                  dim_x=dim_x, \n",
    "                                  init_steps=itstep, \n",
    "                                  delta_sim_steps = dtstep,\n",
    "                                  dx=dx, \n",
    "                                  dt=dt,\n",
    "                                  m_l=m_l, \n",
    "                                  m_r=m_r,\n",
    "                                  n_step=2,\n",
    "                                  gamma=gamma, \n",
    "                                  seed=38921641,\n",
    "                                  device=device)\n",
    "    val_dataset = CahnHillDataset(x_val, y_val, transform_x=lambda x: x[:,None], transform_y=lambda x: x[:,None])\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=1)\n",
    "    \n",
    "    obj = torch.load(weight)\n",
    "    if \"unet\" in key:\n",
    "        model = UNet(in_channels=1, out_channels=1, init_features=64).double().to(device)\n",
    "    elif \"uloop\" in key:\n",
    "        t = int(key.split(\"-\")[-1])\n",
    "        model = UNet_loop(in_channels=1, out_channels=1, init_features=64, temporal=t).double().to(device)\n",
    "    elif \"usolo\" in key:\n",
    "        t = int(key.split(\"-\")[-1])\n",
    "        model = UNet_solo_loop(in_channels=1, out_channels=1, init_features=64, temporal=t).double().to(device)\n",
    "    model.load_state_dict(obj[\"state\"])\n",
    "    \n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    model.eval()\n",
    "    errs = []\n",
    "    for ix in tqdm(range(len(val_dataset))):\n",
    "\n",
    "        item_v = val_dataset[ix]\n",
    "\n",
    "        x = item_v['x'][None][:,0].double().to(device)\n",
    "        y_tru = item_v['y'][None][:,-1].double().to(device) \n",
    "\n",
    "        if \"loop\" in key:\n",
    "            y_prd=model(x)[:,-1]\n",
    "        else:\n",
    "            y_prd=model(x)\n",
    "\n",
    "        im_y1 = y_tru[0,0].detach().cpu().numpy()\n",
    "        im_y2 = y_prd[0,0].detach().cpu().numpy()\n",
    "        errs.append(mae_loss_npy(im_y1, im_y2))\n",
    "#         print(\"mae: {:1.5f}\".format(errs[-1]))\n",
    "#         ch_utils.draw_by_side([im_y1, im_y2], \n",
    "#                               sub_titles=[\"sim\", \"cnn\"], \n",
    "#                               scale=8)\n",
    "    err_dct[key] = errs\n",
    "    print(np.mean(err_dct[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(err_dct)\n",
    "plt.figure(figsize=(18, 12))\n",
    "sns.boxenplot(x=\"variable\", y=\"value\", data=pd.melt(df))\n",
    "plt.ylabel(\"Mean Absolute Error\")\n",
    "plt.xlabel(\"Model Type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(err_dct)\n",
    "plt.figure(figsize=(18, 12))\n",
    "sns.boxenplot(x=\"variable\", y=\"value\", data=pd.melt(df))\n",
    "plt.ylabel(\"Mean Absolute Error\")\n",
    "plt.xlabel(\"Model Type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(err_dct)\n",
    "plt.figure(figsize=(18, 12))\n",
    "sns.boxenplot(x=\"variable\", y=\"value\", data=pd.melt(df))\n",
    "plt.ylabel(\"Mean Absolute Error\")\n",
    "plt.xlabel(\"Model Type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(err_dct)\n",
    "plt.figure(figsize=(18, 12))\n",
    "sns.boxenplot(x=\"variable\", y=\"value\", data=pd.melt(df))\n",
    "plt.ylabel(\"Mean Absolute Error\")\n",
    "plt.xlabel(\"Model Type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(err_dct)\n",
    "sns.boxenplot(x=\"variable\", y=\"value\", data=pd.melt(df))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(err_dct)\n",
    "sns.boxenplot(x=\"variable\", y=\"value\", data=pd.melt(df))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
