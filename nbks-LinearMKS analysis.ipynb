{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from toolz.curried import pipe, curry, compose\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "import chnet.ch_tools as ch_tools\n",
    "import chnet.utilities as ch_utils\n",
    "import chnet.ch_generator as ch_gen\n",
    "from chnet.ch_loader import CahnHillDataset\n",
    "\n",
    "\n",
    "def localization_train(\n",
    "              n_state=5,\n",
    "              domain = (-1.1, 1.1),\n",
    "              mid=0.0, \n",
    "              dif=0.449, \n",
    "              dim_x=96, \n",
    "              dx=0.25, \n",
    "              dt=0.01, \n",
    "              gamma=0.2, \n",
    "              nstep=2,\n",
    "              init_steps=1, \n",
    "              n_samples=1024, \n",
    "              final_tstep=501, \n",
    "              seed=68457542, \n",
    "              device=\"cuda\"):\n",
    "    \n",
    "    from pymks.bases import LegendreBasis\n",
    "    from pymks import MKSLocalizationModel\n",
    "    print(\"Start MKS Training\")\n",
    "    device = torch.device(\"cuda:0\") if device == \"cuda\" else torch.device(\"cpu\")\n",
    "    torch.cuda.empty_cache()\n",
    "    x_inp, y_inp = ch_gen.data_generator(nsamples=n_samples, \n",
    "                                  dim_x=dim_x, \n",
    "                                  init_steps=init_steps, \n",
    "                                  delta_sim_steps = (final_tstep-init_steps)//nstep,\n",
    "                                  dx=dx, \n",
    "                                  dt=dt,\n",
    "                                  m_l=mid-dif, \n",
    "                                  m_r=mid+dif,\n",
    "                                  n_step=nstep,\n",
    "                                  gamma=gamma, \n",
    "                                  seed=seed,\n",
    "                                  device=device)\n",
    "    x_inp, y_inp = x_inp[:,0], y_inp[:,-1]\n",
    "    basis = LegendreBasis(n_state, domain)\n",
    "    model = MKSLocalizationModel(basis)\n",
    "    model.fit(x_inp, y_inp)\n",
    "    print(\"End MKS Training\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def localization_validate(model, \n",
    "                          mid=0.0, \n",
    "                          dif=0.449, \n",
    "                          dim_x=96, \n",
    "                          dx=0.25, \n",
    "                          dt=0.01, \n",
    "                          gamma=0.2, \n",
    "                          nstep=2,\n",
    "                          init_steps=1, \n",
    "                          n_samples=32, \n",
    "                          final_tstep=501, \n",
    "                          seed=8634132, \n",
    "                          device=\"cuda\",\n",
    "                          n_items=5,\n",
    "                          vis=True):\n",
    "    \n",
    "    from chnet.ssim import SSIM\n",
    "    ssim_loss = SSIM(window_size=11)\n",
    "    \n",
    "    mae_loss_npy = lambda x1, x2: np.mean(np.fabs(x1.numpy()-x2.numpy()))\n",
    "\n",
    "    print(\"Start Validation\")\n",
    "    torch.cuda.empty_cache()\n",
    "    x_val, y_val = ch_gen.data_generator(nsamples=n_samples, \n",
    "                                  dim_x=dim_x, \n",
    "                                  init_steps=init_steps, \n",
    "                                  delta_sim_steps = (final_tstep-init_steps)//nstep,\n",
    "                                  dx=dx, \n",
    "                                  dt=dt,\n",
    "                                  m_l=mid-dif, \n",
    "                                  m_r=mid+dif,\n",
    "                                  n_step=nstep,\n",
    "                                  gamma=gamma, \n",
    "                                  seed=seed,\n",
    "                                  device=device)\n",
    "    \n",
    "    x_val, y_val = x_val[:,0], y_val[:,-1]\n",
    "    y_prd = model.predict(x_val)\n",
    "    \n",
    "    errs = []\n",
    "    for ix in tqdm(range(n_samples)):\n",
    "\n",
    "        im_x  = torch.tensor(x_val[ix])\n",
    "        im_y1 = torch.tensor(y_val[ix])\n",
    "        im_y2 = torch.tensor(y_prd[ix])\n",
    "        errs.append(mae_loss_npy(im_y1, im_y2))\n",
    "\n",
    "        if vis:\n",
    "            if ((ix+1) % (n_samples//n_items)) == 0:\n",
    "                ch_utils.draw_by_side([im_x, im_y1, im_y2], \n",
    "                                      sub_titles=[\"inp\", \"sim\", \"cnn\"], \n",
    "                                      scale=8, vmin=None, vmax=None)\n",
    "                \n",
    "\n",
    "                print(\"mae: {}, inp: {:1.3f}, sim: {:1.3f}, cnn: {:1.3f}\".format(errs[-1], \n",
    "                                ssim_loss(im_y1[None, None], im_x[None, None]).item(),\n",
    "                                ssim_loss(im_y1[None, None], im_y1[None, None]).item(), \n",
    "                                ssim_loss(im_y1[None, None], im_y2[None, None]).item()))\n",
    "    return errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_state=5\n",
    "domain = (-1.1, 1.1)\n",
    "mid=0.0\n",
    "dif=1e-4\n",
    "dim_x=96\n",
    "dx=0.25\n",
    "dt=0.01\n",
    "gamma=0.2\n",
    "nstep=6\n",
    "init_steps=1\n",
    "n_samples=2\n",
    "final_tstep=2001\n",
    "seed=68457542\n",
    "device=\"cuda\"\n",
    "device = torch.device(\"cuda:0\") if device == \"cuda\" else torch.device(\"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "micros = {}\n",
    "for mid in [-.3, 0.0, .3]:\n",
    "    \n",
    "    x_inp, y_inp = ch_gen.data_generator(nsamples=n_samples, \n",
    "                                  dim_x=dim_x, \n",
    "                                  init_steps=init_steps, \n",
    "                                  delta_sim_steps = (final_tstep-init_steps)//nstep,\n",
    "                                  dx=dx, \n",
    "                                  dt=dt,\n",
    "                                  m_l=mid-dif, \n",
    "                                  m_r=mid+dif,\n",
    "                                  n_step=nstep,\n",
    "                                  gamma=gamma, \n",
    "                                  seed=seed,\n",
    "                                  device=device)\n",
    "    micros[mid] = x_inp[0]\n",
    "    for i in range(nstep):\n",
    "        print(i*400)\n",
    "        ch_utils.draw_im(x_inp[0,i], vmax=None, vmin=None, title=\"timestep={}\".format(i*400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in [-0.3, 0.0, 0.3]:\n",
    "    ch_utils.draw_by_side([micros[m][ix,...] for ix in range(nstep)], vmax=None, vmin=None, scale=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errs_dct = {}\n",
    "init_steps = [1, 1, 1, 401, 801, 1201, 1601, 2001]\n",
    "final_steps = [101, 401, 801, 801, 1201, 1601, 2001, 2401]\n",
    "for init_step, final_tstep in tqdm(zip(init_steps, final_steps)):\n",
    "    key = \"MKS {}-{}\".format(init_step, final_tstep)\n",
    "    print(key)\n",
    "    \n",
    "    model0 = localization_train(n_state=11,\n",
    "                              dif=0.35, \n",
    "                              init_steps=init_step, \n",
    "                              final_tstep=final_tstep,\n",
    "                              n_samples=2048,)\n",
    "\n",
    "    errs_dct[key] = localization_validate(model0,\n",
    "                                      dif=0.35, \n",
    "                                      init_steps=init_step, \n",
    "                                      final_tstep=final_tstep,\n",
    "                                      n_samples=1024,\n",
    "                                      n_items=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_errs = pd.DataFrame(errs_dct)\n",
    "df_errs.to_csv(\"errs_allMksModels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_errs.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
